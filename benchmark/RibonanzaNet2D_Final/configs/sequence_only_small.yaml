# Model hyperparameters
learning_rate: 0.001  # The learning rate for the optimizer
batch_size: 32        # Number of samples per batch
test_batch_size: 256        # Number of samples per batch
epochs: 20            # Total training epochs
optimizer: "ranger"       # Optimization algorithm
dropout: 0.0     # Dropout regularization rate
weight_decay: 0.0001
k: 9
ninp: 128
nlayers: 9
nclass: 2
ntoken: 5 #AUGC + padding/N token
nhead: 8
use_bpp: False
bpp_file_folder: "../../input/bpp_files_v2.0.3/" #not relevant if not using bpp

# Other configurations
fold: 0
nfolds: 6
input_dir: "../../input/v2.3.2"
gpu_id: "0"
