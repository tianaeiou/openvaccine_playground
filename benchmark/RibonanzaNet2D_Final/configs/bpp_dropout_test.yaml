# Model hyperparameters
learning_rate: 0.001  # The learning rate for the optimizer
batch_size: 32        # Number of samples per batch
test_batch_size: 256        # Number of samples per batch
epochs: 30            # Total training epochs
optimizer: "ranger"       # Optimization algorithm
dropout: 0.0     # Dropout regularization rate
weight_decay: 0.0001
k: 9
ninp: 256
nlayers: 9
nclass: 2
ntoken: 5 #AUGC + padding/N token
nhead: 8
use_bpp: True
bpp_file_folder: "../../input/bpp_files/"
dataset2drop: "none"

# Other configurations
fold: 0
nfolds: 6
input_dir: "../../input/v2.3.2"
gpu_id: "0"
